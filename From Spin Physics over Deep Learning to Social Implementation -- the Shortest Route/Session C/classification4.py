# -*- coding: utf-8 -*-
"""Classification4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ca5nwjyI4FG0cQc5sIvnVPjym6kBdhC9

# Image Classification with Simple Convolution Net

Then Let us introduce more complex input, digit images MNIST.

Following procedure is described as code.
1.   First, weã€€prepare the MNIST dataset, and dataloader for training.
2.   Second, we define a neural netwrork with pytorch to classify.
3.   After that, we train the defined neural network with generated samples. 

Step 1 and 3 is the same as the previous practice. 
The only difference is in the network structure.

## Prepartion 
To use machine learning we should import several modules in colab.
"""

import numpy as np               # for matrix calculation
import matplotlib.pylab as plt      # for data visualization
import torch  # PyTorch deep learning framework
from torch import nn # nn means nerural network module in pytorch
import torchvision # torch image liblaraies
import torchvision.transforms as T # for preprocss of images

from torch.utils.data import DataLoader # DataLoader object

# check for availability of GPU.
print(torch.cuda.is_available())

"""## Data preparation

First, we prepare a dataset. Hereaftre, we use a handwritten digit character dataset called MNIST dataset.
The MNIST is a famous dataset and is available in the `torch` library called `torchvision`. We will use this by pulling it using `torchvision.datasets.MNIST()`. We will preprocess the data and prepare it for use.

There are many other datasets to try, please see the followings:

https://pytorch.org/vision/stable/datasets.html

In this notebook, the dataset folder named ``./data`` will be created to store the MNIST dataset.

As for `torchvision`, it is a collection of image processing libraries for `torch` and provides various image preprocessing functions. In particular, the preprocessing group called `torchvision.transforms` comes in handy when feeding images to learning machines. If you just need to match the tensor format of pytorch, you may not feel much benefit from using only `torchvision.transforms.ToTensor()`, but it is useful when you need to perform operations such as converting pixel values from $[0, 255]$ to $[0, 1]$ or applying normalization.
"""

pre_process = T.ToTensor() # Here preprocess is to transform the digit pattern to the torch tensors

# Get dataset. Here we use './data' folder as the save foloder
# We obtain dataset for training as `Xtrn_data', and for evaluation as 'Xtst_data' respectively:

Xtrn_data = torchvision.datasets.MNIST('./data', download=True, train=True, transform=pre_process)
Xtst_data = torchvision.datasets.MNIST('./data', download=True, train=False, transform=pre_process)


# we prepare data getting object for training iteration.
# The `DataLoader` object can be used for this purpose
Xtrn = DataLoader(Xtrn_data, batch_size=64, shuffle=True)
Xtst = DataLoader(Xtst_data, batch_size=64)

"""## Define a simple Convolution neural network

Here we consider a simple four-layered deep convolution neural network. The 2-dimensional convolution operation assumes the lattice-like input, such as an image. 
Thus, in the convolution neural network, each layer consists of 2-dimensional lattice-like components called channels. So, the input image can be regarded as a chanel with (channel, height, width) = (1, 28, 28) structure.


* `nn.Conv2D()` calculates the convolution operation layer with trainable weights.
* `nn.MaxPool2D()` calculates the pooling operation, which gathers spatially local information in the previous layer. In many cases, the pooling operation compress the channel representation in a half size.

"""

# Redefine 4-layer networks

class DeepCNNClassifier(nn.Module):
    '''
    A deep CNN for MNIST classifier 
    each MNIST data has (1, 28, 28) dimension
    Here, we adopt 4 layers CNN.
    The channel size in the each layer is calculated automatically, so we only direct the number of channels.
    The following has 
    input: (1, 28, 28)
    conv1: (24, 24, 24) -> ReLU -> pool1: (24, 12, 12)
    conv2: (16, 8, 8) -> ReLU -> pool2: (16, 4, 4)
    fc1: (16, 4, 4) -> 100 -> ReLU
    fc2: 100 -> 10
    '''
    def __init__(self):
        '''constructor part, that defins the nn components'''
        super().__init__() 
        # network description
        num_inputs_channel = 1 # input channel dimension
        num_channel1 = 24 # hidden layer1 has 16 channels
        num_channel2 = 16 # hidden layer2 has 16 channles
        num_outputs = 10 # output dimension
        conv_ker_size = 5 # convolution kernel size.
        pool_ker_size = 2 # pooling kernel size
        self.conv1 = nn.Conv2d(num_inputs_channel, num_channel1, conv_ker_size)
        self.conv2 = nn.Conv2d(num_channel1, num_channel2, conv_ker_size)
        self.pool = nn.MaxPool2d(pool_ker_size)

        # here after convolution network structure
        c2size = 4
        fc1size = 100
        self.fc1 = nn.Linear(num_channel2 * c2size * c2size, fc1size)
        self.fc2 = nn.Linear(fc1size, 10)
        # activation definintion
        self.relu = nn.ReLU() # ReLU activation
  
    def forward(self, x):
        '''forward calculation'''
        c1 = self.relu(self.conv1(x))
        p1 = self.pool(c1)
        c2 = self.relu(self.conv2(p1))
        p2 = self.pool(c2)
        z1 = p2.view(p2.size()[0], -1)  # flatten the p2 representation
        z = self.relu(self.fc1(z1))
        y = self.fc2(z) # For Cross-Entropy loss, no activation function is needed.
        return y

# make instance of a defined model
deep_model = DeepCNNClassifier()

# using GPU
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
deep_model.to(device)

# define a loss function (Cross Entropy Loss)
loss_criterion = nn.CrossEntropyLoss()

# define a optimization parameters
learning_rate = 0.01
moment_rate = 0.9
optimizer = torch.optim.SGD(deep_model.parameters(), lr=learning_rate, momentum=moment_rate)

"""OK, Let's run the following. It takes for a while"""

# epoch means the iterations of dataset to train
num_epoch = 15

# to recode loss values in epochs
history = []

for epoch in range(num_epoch):
  for imgs, labels in Xtrn:
    optimizer.zero_grad()
    # inputs = imgs
    inputs = imgs.to(device)  # move to GPU memory
    labels = labels.to(device)

    outputs = deep_model(inputs)
    loss = loss_criterion(outputs, labels) 

    # The parameters will be modified to decrease the loss
    loss.backward()
    optimizer.step()

    # record the history
    history.append(loss.item())


  print(f'Epoch[{epoch+1:02d}/{num_epoch:02d}]: loss = {loss.item():04f}')

# If you'd like to save the data, comments out the following line
# torch.save(model.state_dict(), 'model1.pickl')

plt.plot(np.array(history))
#plt.semilogy(np.array(hist)) # if you'd like to see log-scale
plt.title('Loss Evolution')
plt.xlabel('Epochs')
plt.ylabel('loss')
plt.grid()

correct = 0
total = 0

with torch.no_grad(): # for evaluation no need to parameters update
    for imgs, labels in Xtst:
      inputs = imgs.to(device)  # move to GPU memory
      labels = labels.to(device)
      outputs = deep_model(inputs)
      _, pred = torch.max(outputs.data, 1) # extract the index of the maximum units
      total += labels.size(0) 
      correct += (pred == labels).sum().item()  # sum up correct labels

    acc = float(correct/total) 
    print(f"Accuracy: {acc:.4f}")