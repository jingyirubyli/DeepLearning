# -*- coding: utf-8 -*-
"""Classification3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x32Vdn6aFCUVqXwqOrSSFN-iITv2AlOM

# Image Classification with MLP

Then Let us introduce more complex input, digit images.
We apply MNIST digit dataset hereafter. 

Following procedure is described as code.
1.   First, weã€€prepare the MNIST dataset, and dataloader for training.
2.   Second, we define a neural netwrork with pytorch to classify.
3.   After that, we train the defined neural network with generated samples.

## Prepartion 
To use machine learning we should import several modules in colab.
"""

import numpy as np               # for matrix calculation
import matplotlib.pylab as plt      # for data visualization
import torch  # PyTorch deep learning framework
from torch import nn # nn means nerural network module in pytorch
import torchvision # torch image liblaraies
import torchvision.transforms as T # for preprocss of images

from torch.utils.data import DataLoader # DataLoader object

# check for availability of GPU.
print(torch.cuda.is_available())

"""## Data preparation

First, we prepare a dataset. Hereaftre, we use a handwritten digit character dataset called MNIST dataset.
The MNIST is a famous dataset and is available in the `torch` library called `torchvision`. We will use this by pulling it using `torchvision.datasets.MNIST()`. We will preprocess the data and prepare it for use.

There are many other datasets to try, please see the followings:

https://pytorch.org/vision/stable/datasets.html

In this notebook, the dataset folder named ``./data`` will be created to store the MNIST dataset.

As for `torchvision`, it is a collection of image processing libraries for `torch` and provides various image preprocessing functions. In particular, the preprocessing group called `torchvision.transforms` comes in handy when feeding images to learning machines. If you just need to match the tensor format of pytorch, you may not feel much benefit from using only `torchvision.transforms.ToTensor()`, but it is useful when you need to perform operations such as converting pixel values from $[0, 255]$ to $[0, 1]$ or applying normalization.
"""

pre_process = T.ToTensor() # Here preprocess is to transform the digit pattern to the torch tensors

# Get dataset. Here we use './data' folder as the save foloder
# We obtain dataset for training as `Xtrn_data', and for evaluation as 'Xtst_data' respectively:

Xtrn_data = torchvision.datasets.MNIST('./data', download=True, train=True, transform=pre_process)
Xtst_data = torchvision.datasets.MNIST('./data', download=True, train=False, transform=pre_process)


# we prepare data getting object for training iteration.
# The `DataLoader` object can be used for this purpose
Xtrn = DataLoader(Xtrn_data, batch_size=64, shuffle=True)
Xtst = DataLoader(Xtst_data, batch_size=64)

"""OK, let's see the downloaded images.
Here we use a `DataLoader` object named `Xtrn` as an iterator object; we can obtain an image chank called a batch, whose size is 64.
"""

# get image by use of iterator from Xtrn
imgs, labels = next(iter(Xtrn))

# Let's see the images
plt.figure(figsize=(8, 8))
for cnt in range(64):
    plt.subplot(8, 8, cnt+1)
    img = imgs[cnt][0]  # extract single image, which is the first one(index is cnt), from chunk
    plt.imshow(img, cmap='gray')
    plt.title(int(labels[cnt]))
    plt.axis('off')
    plt.tight_layout()

"""## Define a simple neural network

Here we consider a simple four-layered deep neural network.

"""

# Redefine 4-layer networks

class DeepNNClassifier(nn.Module):
    '''
    A deep NN for MNIST classifier 
    each MNIST data has 28x28 dimension
    Here, we adopt 4 layers NN. 
    These layers have 28x28 - 500 - 250 -10 units.
    '''
    def __init__(self):
        '''constructor part, that defins the nn components'''
        super().__init__() 
        # network description
        num_inputs = 28 * 28 * 1 # input dimension
        num_hidden1 = 500 # hidden layer1
        num_hidden2 = 250 # hidden layer2
        num_outputs = 10 # output dimension
        self.l1 = nn.Linear(num_inputs, num_hidden1, bias=True)
        self.l2 = nn.Linear(num_hidden1, num_hidden2, bias=True)
        self.l3 = nn.Linear(num_hidden2, num_outputs, bias=True)
        self.relu = nn.ReLU() # ReLU activation
  
    def forward(self, x):
        '''forward calculation'''
        z1 = self.relu(self.l1(x))
        z2 = self.relu(self.l2(z1))
        y = self.l3(z2) # For Cross-Entropy loss, no activation function is needed.
        return y

# make instance of a defined model
deep_model = DeepNNClassifier()

# define a loss function (Cross Entropy Loss)
loss_criterion = nn.CrossEntropyLoss()

# define a optimization parameters
learning_rate = 0.01
moment_rate = 0.9
optimizer = torch.optim.SGD(deep_model.parameters(), lr=learning_rate, momentum=moment_rate)

# using GPU
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
deep_model.to(device)

"""OK, Let's run the following. It takes for a while"""

# epoch means the iterations of dataset to train
num_epoch = 15

# to recode loss values in epochs
history = []

for epoch in range(num_epoch):
  for imgs, labels in Xtrn:
    imgsize = 28 * 28

    optimizer.zero_grad()
    inputs = imgs.view(-1, imgsize) # transform 28 x 28 img into 1 dimensional vector

    # using GPU
    inputs = inputs.to(device)
    labels = labels.to(device)

    outputs = deep_model(inputs)
    loss = loss_criterion(outputs, labels) 

    # The parameters will be modified to decrease the loss
    loss.backward()
    optimizer.step()

    # record the history
    history.append(loss.item())


  print(f'Epoch[{epoch+1:02d}/{num_epoch:02d}]: loss = {loss.item():04f}')

# If you'd like to save the data, comments out the following line
# torch.save(model.state_dict(), 'model1.pickl')

plt.plot(np.array(history))
#plt.semilogy(np.array(hist)) # if you'd like to see log-scale
plt.title('Loss Evolution')
plt.xlabel('Epochs')
plt.ylabel('loss')
plt.grid()

correct = 0
total = 0

with torch.no_grad(): # for evaluation no need to parameters update
    for imgs, labels in Xtst:
        imgsize = 28 * 28

        inputs = imgs.view(-1, imgsize)

        # using GPU
        inputs = inputs.to(device)
        labels = labels.to(device)

        outputs = deep_model(inputs)
        _, pred = torch.max(outputs.data, 1) # extract the index of the maximum units
        total += labels.size(0)
        correct += (pred == labels).sum().item()  # sum up correct labels

    acc = float(correct/total) 
    print(f"Accuracy: {acc:.4f}")